name: Run Walmart Scraper

on:
  workflow_dispatch:
  schedule:
    - cron: '*/5 * * * *' # Every 5 minutes

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: false # Use PAT manually

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libx11-dev \
            libx11-xcb1 \
            libxcomposite1 \
            libxcursor1 \
            libxdamage1 \
            libxi6 \
            libxtst6 \
            libnss3 \
            libatk-bridge2.0-0 \
            libgtk-3-0 \
            libdrm2 \
            libgbm1 \
            libasound2t64

      - name: Install Node.js dependencies
        run: npm install

      - name: Install Chromium for Puppeteer
        run: npx puppeteer browsers install chrome

      - name: Run scraper
        run: node WalmartTrigerData.js

      - name: Commit and push updated data
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add walmart-data.csv walmart-data.json
          git commit -m "ðŸ”„ Auto update scraped data - $(date)" || echo "No changes to commit"
          git push https://x-access-token:${{ secrets.MY_GITHUB_PAT }}@github.com/${{ github.repository }}.git HEAD:main
        env:
          MY_GITHUB_PAT: ${{ secrets.MY_GITHUB_PAT }}
